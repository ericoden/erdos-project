{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import time\n",
    "import xgboost as xgb\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "font = {'size': 18}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data/train.pkl\")\n",
    "df['viral'] = df['score'] >= 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>viral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54442</th>\n",
       "      <td>n97ehm</td>\n",
       "      <td>weremanthing</td>\n",
       "      <td>Refinance my home to free up VA loan or wait?</td>\n",
       "      <td>First let me say thank you for looking at my p...</td>\n",
       "      <td>11:20:52</td>\n",
       "      <td>2021-05-10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41531</th>\n",
       "      <td>nzf89i</td>\n",
       "      <td>b1ackcat</td>\n",
       "      <td>Thank you for being such a great resource; you...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>01:08:32</td>\n",
       "      <td>2021-06-14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61126</th>\n",
       "      <td>mxntnt</td>\n",
       "      <td>runnerup</td>\n",
       "      <td>401k vs 457b, not sure which to max first</td>\n",
       "      <td>My work has both the 401k and 457b plans. They...</td>\n",
       "      <td>12:50:32</td>\n",
       "      <td>2021-04-24</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87222</th>\n",
       "      <td>lg8t6y</td>\n",
       "      <td>Bunburier</td>\n",
       "      <td>Student Loans, Interest Rate, and Payment Stra...</td>\n",
       "      <td>I'll be attending graduate school soon. Tuitio...</td>\n",
       "      <td>12:44:56</td>\n",
       "      <td>2021-02-09</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34549</th>\n",
       "      <td>obzx08</td>\n",
       "      <td>Mxnchkinz_</td>\n",
       "      <td>What do I put under Gross Income when applying...</td>\n",
       "      <td>I'm applying for a Discover Secured Credit Car...</td>\n",
       "      <td>21:27:28</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        author  \\\n",
       "54442  n97ehm  weremanthing   \n",
       "41531  nzf89i      b1ackcat   \n",
       "61126  mxntnt      runnerup   \n",
       "87222  lg8t6y     Bunburier   \n",
       "34549  obzx08    Mxnchkinz_   \n",
       "\n",
       "                                                   title  \\\n",
       "54442      Refinance my home to free up VA loan or wait?   \n",
       "41531  Thank you for being such a great resource; you...   \n",
       "61126          401k vs 457b, not sure which to max first   \n",
       "87222  Student Loans, Interest Rate, and Payment Stra...   \n",
       "34549  What do I put under Gross Income when applying...   \n",
       "\n",
       "                                                selftext      time  \\\n",
       "54442  First let me say thank you for looking at my p...  11:20:52   \n",
       "41531                                          [removed]  01:08:32   \n",
       "61126  My work has both the 401k and 457b plans. They...  12:50:32   \n",
       "87222  I'll be attending graduate school soon. Tuitio...  12:44:56   \n",
       "34549  I'm applying for a Discover Secured Credit Car...  21:27:28   \n",
       "\n",
       "             date  score  num_comments  viral  \n",
       "54442  2021-05-10      1             2  False  \n",
       "41531  2021-06-14      1             2  False  \n",
       "61126  2021-04-24      3             7  False  \n",
       "87222  2021-02-09      2             2  False  \n",
       "34549  2021-07-01      0            15  False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Document Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the GoogleNews word vector data frame (downloaded in \"nlp_modeling_v2\"), with words restricted to those appearing in the titles of the posts. Each row is indexed by a word, and has 300 numerical rows corresponding to the word vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs = pd.read_pickle(\"data/word_vec_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(word_vecs.index) # get list of words in the word vector data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each title, compute the document vector, which is merely the mean of the word vectors for the words in the title, if they exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english')) # had to run \"import nltk & nltk.download('stopwords')\" before this worked\n",
    "def get_doc_vec(text):\n",
    "    text = text.lower()\n",
    "    doc = word_tokenize(text)\n",
    "    doc = [word for word in doc if word not in stop_words]\n",
    "    doc = [word for word in doc if word.isalpha()]\n",
    "    doc = [word for word in doc if word in vocab]\n",
    "    word_vectors = [word_vecs.loc[word] for word in doc]\n",
    "    if len(word_vectors) > 0:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 100.44 seconds\n"
     ]
    }
   ],
   "source": [
    "tic = time.perf_counter()\n",
    "x = []\n",
    "for title in df.title:\n",
    "    x.append(get_doc_vec(title))\n",
    "toc = time.perf_counter()\n",
    "print(f\"Took {toc - tic:0.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use PCA to reduce the dimension of the document vectors from 300 to 15, making it more tractable for running machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 15, random_state=10)\n",
    "\n",
    "reduced_vecs = pca.fit_transform(x)\n",
    "toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Vector Visualization\n",
    "\n",
    "Applying t-distributed Stochastic Neighbor Embedding (t-SNE) to convert the 15 dimensional document vectors to 2 dimensions, and visualizing the viral and nonviral tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "num_rows = 1000\n",
    "viral_list = list(df.viral)[:num_rows]\n",
    "viral_indices = [i for i in range(len(list(df.viral)[:num_rows])) if viral_list[i]==True]\n",
    "nonviral_indices = [i for i in range(len(list(df.viral)[:num_rows])) if viral_list[i]==False]\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "for perp in range(5,100):\n",
    "    tsne = TSNE(n_components = 2, init = 'random', random_state = 10, perplexity = perp)\n",
    "    squished_vecs = tsne.fit_transform(reduced_vecs[:num_rows])\n",
    "    plt.clf()\n",
    "    plt.scatter([s[0] for s in squished_vecs[nonviral_indices]], [s[1] for s in squished_vecs[nonviral_indices]], alpha=0.1, color='red', label='nonviral')\n",
    "    plt.scatter([s[0] for s in squished_vecs[viral_indices]], [s[1] for s in squished_vecs[viral_indices]], alpha=0.5, color='blue', label='viral')\n",
    "    plt.title(f'Perplexity: {perp}')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a copy of the original data frame and append the 15 dimensional document vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>viral</th>\n",
       "      <th>docvec_0</th>\n",
       "      <th>...</th>\n",
       "      <th>docvec_5</th>\n",
       "      <th>docvec_6</th>\n",
       "      <th>docvec_7</th>\n",
       "      <th>docvec_8</th>\n",
       "      <th>docvec_9</th>\n",
       "      <th>docvec_10</th>\n",
       "      <th>docvec_11</th>\n",
       "      <th>docvec_12</th>\n",
       "      <th>docvec_13</th>\n",
       "      <th>docvec_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54442</th>\n",
       "      <td>n97ehm</td>\n",
       "      <td>weremanthing</td>\n",
       "      <td>Refinance my home to free up VA loan or wait?</td>\n",
       "      <td>First let me say thank you for looking at my p...</td>\n",
       "      <td>11:20:52</td>\n",
       "      <td>2021-05-10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.453273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154068</td>\n",
       "      <td>0.247290</td>\n",
       "      <td>-0.254865</td>\n",
       "      <td>-0.074706</td>\n",
       "      <td>0.012286</td>\n",
       "      <td>-0.209845</td>\n",
       "      <td>-0.142833</td>\n",
       "      <td>-0.121779</td>\n",
       "      <td>0.034462</td>\n",
       "      <td>-0.057537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41531</th>\n",
       "      <td>nzf89i</td>\n",
       "      <td>b1ackcat</td>\n",
       "      <td>Thank you for being such a great resource; you...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>01:08:32</td>\n",
       "      <td>2021-06-14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.328374</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117939</td>\n",
       "      <td>0.173250</td>\n",
       "      <td>-0.135397</td>\n",
       "      <td>0.072369</td>\n",
       "      <td>-0.076752</td>\n",
       "      <td>0.038594</td>\n",
       "      <td>0.045877</td>\n",
       "      <td>-0.039308</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>0.057338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61126</th>\n",
       "      <td>mxntnt</td>\n",
       "      <td>runnerup</td>\n",
       "      <td>401k vs 457b, not sure which to max first</td>\n",
       "      <td>My work has both the 401k and 457b plans. They...</td>\n",
       "      <td>12:50:32</td>\n",
       "      <td>2021-04-24</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.441687</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.149564</td>\n",
       "      <td>0.233118</td>\n",
       "      <td>-0.383484</td>\n",
       "      <td>-0.023185</td>\n",
       "      <td>-0.091743</td>\n",
       "      <td>-0.216232</td>\n",
       "      <td>0.122335</td>\n",
       "      <td>0.018077</td>\n",
       "      <td>-0.125292</td>\n",
       "      <td>-0.116175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87222</th>\n",
       "      <td>lg8t6y</td>\n",
       "      <td>Bunburier</td>\n",
       "      <td>Student Loans, Interest Rate, and Payment Stra...</td>\n",
       "      <td>I'll be attending graduate school soon. Tuitio...</td>\n",
       "      <td>12:44:56</td>\n",
       "      <td>2021-02-09</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.519265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090096</td>\n",
       "      <td>-0.137941</td>\n",
       "      <td>-0.072417</td>\n",
       "      <td>-0.186384</td>\n",
       "      <td>0.125709</td>\n",
       "      <td>-0.043674</td>\n",
       "      <td>-0.138492</td>\n",
       "      <td>0.330588</td>\n",
       "      <td>-0.011789</td>\n",
       "      <td>-0.202053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34549</th>\n",
       "      <td>obzx08</td>\n",
       "      <td>Mxnchkinz_</td>\n",
       "      <td>What do I put under Gross Income when applying...</td>\n",
       "      <td>I'm applying for a Discover Secured Credit Car...</td>\n",
       "      <td>21:27:28</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>0.347807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.323602</td>\n",
       "      <td>0.068687</td>\n",
       "      <td>0.033118</td>\n",
       "      <td>0.019221</td>\n",
       "      <td>-0.153715</td>\n",
       "      <td>0.081396</td>\n",
       "      <td>0.043083</td>\n",
       "      <td>-0.259490</td>\n",
       "      <td>-0.025280</td>\n",
       "      <td>-0.085683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        author  \\\n",
       "54442  n97ehm  weremanthing   \n",
       "41531  nzf89i      b1ackcat   \n",
       "61126  mxntnt      runnerup   \n",
       "87222  lg8t6y     Bunburier   \n",
       "34549  obzx08    Mxnchkinz_   \n",
       "\n",
       "                                                   title  \\\n",
       "54442      Refinance my home to free up VA loan or wait?   \n",
       "41531  Thank you for being such a great resource; you...   \n",
       "61126          401k vs 457b, not sure which to max first   \n",
       "87222  Student Loans, Interest Rate, and Payment Stra...   \n",
       "34549  What do I put under Gross Income when applying...   \n",
       "\n",
       "                                                selftext      time  \\\n",
       "54442  First let me say thank you for looking at my p...  11:20:52   \n",
       "41531                                          [removed]  01:08:32   \n",
       "61126  My work has both the 401k and 457b plans. They...  12:50:32   \n",
       "87222  I'll be attending graduate school soon. Tuitio...  12:44:56   \n",
       "34549  I'm applying for a Discover Secured Credit Car...  21:27:28   \n",
       "\n",
       "             date  score  num_comments  viral  docvec_0  ...  docvec_5  \\\n",
       "54442  2021-05-10      1             2  False  0.453273  ...  0.154068   \n",
       "41531  2021-06-14      1             2  False -0.328374  ... -0.117939   \n",
       "61126  2021-04-24      3             7  False -0.441687  ... -0.149564   \n",
       "87222  2021-02-09      2             2  False  0.519265  ...  0.090096   \n",
       "34549  2021-07-01      0            15  False  0.347807  ... -0.323602   \n",
       "\n",
       "       docvec_6  docvec_7  docvec_8  docvec_9  docvec_10  docvec_11  \\\n",
       "54442  0.247290 -0.254865 -0.074706  0.012286  -0.209845  -0.142833   \n",
       "41531  0.173250 -0.135397  0.072369 -0.076752   0.038594   0.045877   \n",
       "61126  0.233118 -0.383484 -0.023185 -0.091743  -0.216232   0.122335   \n",
       "87222 -0.137941 -0.072417 -0.186384  0.125709  -0.043674  -0.138492   \n",
       "34549  0.068687  0.033118  0.019221 -0.153715   0.081396   0.043083   \n",
       "\n",
       "       docvec_12  docvec_13  docvec_14  \n",
       "54442  -0.121779   0.034462  -0.057537  \n",
       "41531  -0.039308   0.005682   0.057338  \n",
       "61126   0.018077  -0.125292  -0.116175  \n",
       "87222   0.330588  -0.011789  -0.202053  \n",
       "34549  -0.259490  -0.025280  -0.085683  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vec_df = pd.DataFrame(reduced_vecs)\n",
    "doc_vec_df['title'] = list(df.title)\n",
    "df2 = df.copy(deep=True)\n",
    "for i in range(15):\n",
    "    df2['docvec_'+str(i)] = list(doc_vec_df[i])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract more data from columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['hour'] = [dt.hour for dt in df2['time']]\n",
    "df2['weekday'] = [dt.weekday() for dt in df2['date']]\n",
    "df2['ismorning'] = [hour in [6,7,8,9] for hour in list(df2['hour'])]\n",
    "df2['isweekend'] = [weekday in [5, 6] for weekday in list(df2['weekday'])]\n",
    "df2['chars_in_title'] = [len(title) for title in df2['title']]\n",
    "df2['words_in_title'] = [len(title.split()) for title in df2['title']]\n",
    "df2['chars_in_selftext'] = [len(str(selftext)) for selftext in df2['selftext']]\n",
    "df2['words_in_selftext'] = [len(str(selftext).split()) for selftext in df2['selftext']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = pd.get_dummies(df2, columns=['hour', 'weekday']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cols_to_drop = ['id', 'author', 'title', 'selftext', 'time', 'date', 'score', 'num_comments']\n",
    "df3 = df2.drop(cols_to_drop, axis=1)\n",
    "\n",
    "# separate the features and the response\n",
    "X = df3.drop('viral', axis=1)\n",
    "y = df3['viral']\n",
    "\n",
    "# put 80% of data into training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['docvec_0',\n",
       " 'docvec_1',\n",
       " 'docvec_2',\n",
       " 'docvec_3',\n",
       " 'docvec_4',\n",
       " 'docvec_5',\n",
       " 'docvec_6',\n",
       " 'docvec_7',\n",
       " 'docvec_8',\n",
       " 'docvec_9',\n",
       " 'docvec_10',\n",
       " 'docvec_11',\n",
       " 'docvec_12',\n",
       " 'docvec_13',\n",
       " 'docvec_14',\n",
       " 'hour',\n",
       " 'weekday',\n",
       " 'ismorning',\n",
       " 'isweekend',\n",
       " 'chars_in_title',\n",
       " 'words_in_title',\n",
       " 'chars_in_selftext',\n",
       " 'words_in_selftext']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerset(s):\n",
    "    power_set = []\n",
    "    x = len(s)\n",
    "    for i in range(1 << x):\n",
    "        power_set.append([s[j] for j in range(x) if (i & (1 << j))])\n",
    "        \n",
    "    return power_set[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************\n",
      "Features: ['isweekend', 'chars_in_selftext', 'ismorning', 'words_in_title']\n",
      "Precision: 0.167\n",
      "Recall: 0.002\n",
      "f1: 0.004\n",
      "Best f1: 0.004024144869215291\n",
      "Best f1 features: ['isweekend', 'chars_in_selftext', 'ismorning', 'words_in_title']\n"
     ]
    }
   ],
   "source": [
    "doc_vec = ['docvec_'+str(i) for i in range(15)]\n",
    "feature_list = powerset(['ismorning', \n",
    "                         'isweekend', 'chars_in_title', 'words_in_title', \n",
    "                         'chars_in_selftext', 'words_in_selftext'])\n",
    "#feature_list = [['isweekend', 'chars_in_selftext', 'ismorning', 'words_in_title']]\n",
    "feature_list = [feature + doc_vec for feature in feature_list]\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "max_f1 = 0\n",
    "max_f1_features = []\n",
    "\n",
    "for features in feature_list:\n",
    "    model.fit(X_train[features], y_train)\n",
    "    preds = model.predict(X_test[features])\n",
    "    precision = precision_score(y_test, preds)\n",
    "    recall = recall_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    if f1 > max_f1:\n",
    "        max_f1 = f1\n",
    "        max_f1_features = list(set(features) - set(doc_vec))\n",
    "    print(\"*************\")\n",
    "    print(\"Features:\", list(set(features) - set(doc_vec)))\n",
    "    print(f\"Precision: {precision:.3f}\")\n",
    "    print(f\"Recall: {recall:.3f}\")\n",
    "    print(f\"f1: {f1:.3f}\")\n",
    "print(\"Best f1:\", max_f1)\n",
    "print(\"Best f1 features:\", max_f1_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24493,     5],\n",
       "       [  490,     1]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
